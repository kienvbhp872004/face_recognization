{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-03T20:25:31.598688Z",
     "start_time": "2025-07-03T20:24:54.702783Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from facenet_pytorch import MTCNN,InceptionResnetV1\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "class FaceLoading:\n",
    "    def __init__(self,directory):\n",
    "        self.directory = directory\n",
    "        self.target_size = (112, 112)\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.mtcnn = MTCNN(image_size=160, margin=0, min_face_size=20,\n",
    "            thresholds=[0.6, 0.7, 0.7], factor=0.709, post_process=True)\n",
    "        self.i = 1\n",
    "    def extract_face(self,path):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        face = self.mtcnn(img)\n",
    "        return face\n",
    "    def load_face_and_class(self):\n",
    "        for sub_dir in os.listdir(self.directory):\n",
    "            sub_dir_path = os.path.join(self.directory, sub_dir)\n",
    "            for img_name in os.listdir(sub_dir_path):\n",
    "                face = self.extract_face(os.path.join(sub_dir_path, img_name))\n",
    "                if(face is not None):\n",
    "                    self.X.append(face)\n",
    "                    self.y.append(sub_dir)\n",
    "        return np.array(self.X), np.array(self.y)\n",
    "    def plot_images(self):\n",
    "        num_columns = 3\n",
    "        num_rows = math.ceil(len(self.X) / num_columns)  # Ensure row count covers all images\n",
    "\n",
    "        plt.figure(figsize=(num_columns * 3, num_rows * 3))  # Adjust figure size dynamically\n",
    "        for num, img in enumerate(self.X):\n",
    "            plt.subplot(num_rows, num_columns, num + 1)\n",
    "            plt.imshow(img.permute(1, 2, 0).numpy())\n",
    "            plt.axis('off')\n",
    "        plt.tight_layout()  # Improve layout spacing\n",
    "        plt.show()\n",
    "face_loading = FaceLoading(r\"C:\\Users\\admin\\OneDrive - Hanoi University of Science and Technology\\Documents\\GitHub\\PTTK\\face_recognization\\source\\data_raw\\image\")\n",
    "X,y = face_loading.load_face_and_class()\n",
    "encode = LabelEncoder()\n",
    "encoded_y = encode.fit_transform(y)\n",
    "encoded_y = encoded_y.reshape(-1, 1)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)  # sparse_output=False để trả về mảng NumPy\n",
    "onehot_y = onehot_encoder.fit_transform(encoded_y)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "resnet = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "# Assuming resnet is your InceptionResnetV1 model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Preprocessing pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((160, 160)),  # Resize to 160x160\n",
    "    transforms.ToTensor(),          # Converts to (C, H, W) and normalizes to [0, 1]\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "X_embed = []\n",
    "for face in X:\n",
    "    if isinstance(face, np.ndarray):\n",
    "        # Check shape and type\n",
    "        # print(f\"Shape: {face.shape}, Dtype: {face.dtype}\")\n",
    "\n",
    "        # Ensure face is a valid image array\n",
    "        if face.ndim == 3:\n",
    "            if face.shape[-1] in [1, 3]:  # (H, W, C) format\n",
    "                if face.shape[-1] == 1:  # Convert grayscale to RGB\n",
    "                    face = np.repeat(face, 3, axis=-1)\n",
    "            elif face.shape[0] in [1, 3]:  # (C, H, W) format\n",
    "                face = face.transpose(1, 2, 0)  # Convert to (H, W, C)\n",
    "                if face.shape[-1] == 1:  # Convert grayscale to RGB\n",
    "                    face = np.repeat(face, 3, axis=-1)\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid face shape: {face.shape}. Expected (H, W, 3), (H, W, 1), or (3, H, W).\")\n",
    "        elif face.ndim == 2:  # Grayscale (H, W)\n",
    "            face = np.stack([face] * 3, axis=-1)  # Convert to RGB\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid face shape: {face.shape}. Expected (H, W, 3), (H, W, 1), or (H, W).\")\n",
    "\n",
    "        # Ensure uint8 for PIL (if float, convert to uint8)\n",
    "        if face.dtype != np.uint8:\n",
    "            face = (face * 255).clip(0, 255).astype(np.uint8)\n",
    "\n",
    "        face_pil = Image.fromarray(face)\n",
    "\n",
    "        # Apply preprocessing\n",
    "        face_tensor = preprocess(face_pil).unsqueeze(0).to(device)  # Shape: [1, 3, 160, 160]\n",
    "\n",
    "        # Get embedding\n",
    "        with torch.no_grad():\n",
    "            embedding = resnet(face_tensor).cpu().detach().numpy()\n",
    "        X_embed.append(embedding)\n",
    "    else:\n",
    "        raise ValueError(\"Each face in X should be a NumPy array\")\n",
    "\n",
    "X_embed = np.array(X_embed)\n",
    "\n",
    "# Lưu embedding và nhãn\n",
    "print(\"Đang lưu embedding và nhãn...\")\n",
    "\n",
    "# Reshape embedding để loại bỏ dimension thừa\n",
    "X_embed = X_embed.reshape(X_embed.shape[0], -1)\n",
    "\n",
    "np.save('face_embeddings.npy', X_embed)\n",
    "print(f\"Đã lưu embedding với shape: {X_embed.shape}\")\n",
    "\n",
    "np.save('face_labels.npy', y)\n",
    "print(f\"Đã lưu nhãn gốc: {len(y)} samples\")\n"
   ],
   "id": "c2a724ef6e6781c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đang lưu embedding và nhãn...\n",
      "Đã lưu embedding với shape: (87, 512)\n",
      "Đã lưu nhãn gốc: 87 samples\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "f86659822cf13233"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-04T02:27:58.893959Z",
     "start_time": "2025-07-04T02:27:58.864571Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Chia tập dữ liệu thành tập huấn luyện và tập kiểm tra (3:1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_embed, y, test_size=0.25, stratify=y, random_state=42)\n",
    "\n",
    "# Chuyển đổi nhãn thành số nguyên\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Tính độ tương đồng cosine giữa các embedding trong tập kiểm tra\n",
    "cos_sim_matrix = cosine_similarity(X_test)\n",
    "\n",
    "# Khởi tạo danh sách để lưu nhãn dự đoán\n",
    "y_pred = []\n",
    "\n",
    "# Đặt ngưỡng 70% (0.7) cho độ tương đồng cosine\n",
    "threshold = 0.7\n",
    "\n",
    "# So sánh từng cặp embedding trong tập kiểm tra\n",
    "for i in range(len(X_test)):\n",
    "    max_sim = -1\n",
    "    predicted_label = y_test_encoded[i]  # Mặc định là nhãn gốc nếu không tìm thấy cặp tương đồng\n",
    "    for j in range(len(X_test)):\n",
    "        if i != j and cos_sim_matrix[i][j] > max_sim and cos_sim_matrix[i][j] >= threshold:\n",
    "            max_sim = cos_sim_matrix[i][j]\n",
    "            predicted_label = y_test_encoded[j]\n",
    "    y_pred.append(predicted_label)\n",
    "\n",
    "# Tính các chỉ số đánh giá\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "precision = precision_score(y_test_encoded, y_pred, average='weighted')\n",
    "recall = recall_score(y_test_encoded, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test_encoded, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "\n",
    "\n"
   ],
   "id": "f29e566ba54a21c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n"
     ]
    }
   ],
   "execution_count": 15
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
